<img width="1620" height="590" alt="1231" src="https://github.com/user-attachments/assets/d46813ce-09d9-4f41-958a-044e8a77f4ba" />

<br/>
<br/>

# 0. Getting Started (시작하기)

본 프로젝트는 ROS2 및 Python 기반의 자율주행 로봇 및 모니터링 시스템입니다.
* **[Jetson Orin Nano]** 로봇 구동 및 CV/센서 통합 모듈 실행
* **[관리자 시스템]** Streamlit 기반 모니터링 시스템 실행

<br/>

# 1. Project Overview (프로젝트 개요)

* **프로젝트 이름:** **PORTY (포티)**
* **프로젝트 설명:**
    * 항만시설의 보안 경비 시스템 구축 및 무인화
    * 밀입국, 불법 낚시 등 인명 사고 및 각종 사고로 인한 자원 손실 발생과 기존 경비 시스템의 한계 발생 극복
    * 항만 내 자율 순찰 및 CV와 센서를 통한 이상 상황 감지 보안 경고 알림 제공시스템 제작

## 1.1. 작품의 개발배경 및 필요성

2023년 보령 대천항에 중국인 22인이 밀입국한 사건과 2024년 여수광양항만에 민간인 3인이 무단 출입하여 국가 중요 보안구역을 촬영한 사건 등을 접하며 항만 시설의 보안 시스템 보충에 필요성을 느낌. 또한, 항만하역업에서 발생한 다수의 사고원인이 현장 내 감시 부족과 순찰 미흡임을 깨닫고, 항만 내 보안 사각지대 문제가 심각함을 파악함. 이를 해결하고자, 불법 침입자 감지 및 각종 이상 상황 탐지가 가능한 자율주행 경비 로봇을 통해 실시간 순찰을 수행함으로써 사고 예방 효과를 기대할 수 있음.

## 1.2. 작품의 특장점

1.  **SLAM 기반 자율 순찰**
    * LiDAR 센서와 SLAM 알고리즘을 결합하여 실외 환경의 지도를 실시간 작성하고, 안전한 경로를 스스로 탐색함
    * 기존 보안 장비가 고정된 시야만 제공하는 것과 달리, 동적인 자율 주행 순찰이 가능하여 보안 사각지대를 최소화함
2.  **지능형 침입자 감지**
    * YOLO를 적용하여 허가되지 않은 인물이나 특정 객체를 실시간으로 탐지함
3.  **안전한 주행을 위한 장애물 회피**
    * LiDAR을 통해 주변 장애물을 감지하고 충돌을 회피함
    * 동적 환경에서도 안정적인 주행을 보장하여 장시간 무인 순찰이 가능함
4.  **이상 상황 감지 및 대응**
    * 화재, 가스, 기상 변화 등 다양한 비상 상황을 실시간 감지하고 자동으로 알림·대응함

## 1.3. 작품 기능

1.  **SLAM 기반 자율 순찰** : LiDAR를 활용해 실외 지도 작성 및 경로 탐색
2.  **침입자 감지** : YOLO를 활용해 허가되지 않는 인물 탐지
3.  **경보 시스템** : MQTT 프로토콜을 이용해 관리자에게 알림
4.  **장애물 회피** : 적외선 거리 센서를 활용하여 충돌 방지
5.  **로봇 자율 주행 제어** : 환경에서 원활히 주행할 수 있도록 로봇 구조 설계
6.  **이상 상황 감지 및 처리 알고리즘** : 가스, 화재 등 상황별 알고리즘 처리

## 1.4. 작품의 기대효과 및 활용분야

1.  무인 보안 시스템 구축 및 실시간 경비 업무 자동화를 통해 비용 절감과 운영 효율 극대화 및 보안 사고 예방
2.  기존 CCTV, 경비 인력 중심의 감시 시스템에서 벗어나 자율주행 기반 경비 로봇을 활용해 보안 사각지대 해소 및 24시간 무인 순찰 체계 실현
3.  실제 기업과 협력하면서 경비 로봇의 상용화 가능성을 확인할 수 있으며, 다양한 분야에 적용할 수 있을 것으로 예상. 또한, 특허 출원 및 상용화 과정에 참여하면서 PORTY 로봇의 경쟁력 확대 예상.
    * 기업과의 공동개발을 통해 경비 로봇의 시제품을 제작함으로써 실제 현장 적용성과 상용화 가능성을 구체적으로 확인할 수 있을 것으로 기대. 또한 특허 출원과 상용화 추진 과정에서 기술 완성도와 경쟁력을 강화하여 PORTY 로봇의 시장성을 확인 예정

<br/>
<br/>

# 2. Team Members (팀원 및 팀 소개)

| 허지윤 | 강지윤 | 조윤정 | 현희섭 |
|:------:|:------:|:------:|:------:|
| 지능기전공학과 23| AI로봇학과 24| 지능기전공학과 23| 지능기전공학부 21<br/>무인이동체공학전공|
| <div align="center"><img src="https://github.com/user-attachments/assets/b7c009ae-b82b-40b9-8c23-06eac99e195f" alt="허찌허찌" height="260"/></div> | <div align="center"><img src="https://github.com/user-attachments/assets/0307cb45-649d-4977-b107-5d7a0b6068c8" alt="지윤지윤" height="260"/></div> | <div align="center"><img src="https://github.com/user-attachments/assets/35aec41b-bd36-4978-8841-abef9e09ccd4" alt="윤정윤정" height="260"/></div> | <div align="center"><img src="https://github.com/user-attachments/assets/47b20933-c912-4c3e-88d8-1cf326ef5178" alt="희섭희섭" height="260"/></div> |
| 전반적인 프로젝트 관리, 자율주행, 센서 제어, 구동부 설계 | CV 모델(화재, 작업복), 모니터링 시스템 제작 | CV 모델 적용(균열), 통합 및 최적화, DB 연동 | 센서 제어, 구동부 설계, 자율주행 |
| 회의 일정 계획 및 프로젝트 주도, 아두이노, 젯슨 오린, SLAM | CV 화재 감지, 안전복(Hivis) 감지, Streamlit, 시연 환경 조성 | CV 균열 감지, 젯슨 오린 최적화 및 ROS2 파이프라인, MongoDB 연동 | 아두이노, 젯슨 오린, SLAM, 구동, Nav2 |
| [GitHub](https://github.com/JYsaemyo) | [GitHub](https://github.com/artistyun) | [GitHub](https://github.com/yoonie03) | [GitHub](https://github.com/sub-sway) |

<br/>
<br/>

# 3. Project Details (작품 상세 개요)

### 3.1. 기획 의도 및 배경

1.  **항만시설 보안 관련 법제와 과제**
    * 항만시설은 「경비업법 시행령」 제2조에서 규정한 국가중요 보안시설에 해당하기에 「통합방위법」 및 관련 법령에 근거하여 국가적 차원의 보호와 관리가 필요한 보안시설로 정의됨
    * 「항만법」 제33조에 따라 위해물품 반입·은닉, 지정 구역 무단 출입 및 허가 없는 촬영 행위가 금지됨. 2024년 개정으로 촬영 결과물 배포 또한 금지됨
    * 「항만법」 제31조(CCTV 설치 의무화) 및 「국제선박항만보안법 시행규칙」 등에 따라 보안 인력 확보가 규정되어 있으나, 실제로는 CCTV와 인력 경비만으로는 보안 사각지대 발생 및 밀입국·무단 출입 등 사건 예방에 한계가 있음
    * 따라서 법적 의무사항을 넘어서는 첨단 기술 기반 보안 체계가 필요함
      
2.  **기획 의도**
    * 「항만하역업 안전관리 개선방안에 관한 연구」(2023, 민섭 심 외)에 따르면, 2016~2020년간 항만하역업 사고의 61.6%가 현장 내 감시 부족과 순찰 미흡에 따른 안전 사고로 보고 됨.
    * 2023년 보령 대천항 중국인 밀입국 사건과 2024년 여수광양항만 민간인 무단 촬영 사건을 보고 항만시설의 보안 시스템 보완의 필요성을 느낌.
    * 방파제, 해안가 등 위험 구역에서 발생하는 불법 출입, 낚시, 화재, 가스 누출 등의 사고에 대비할 로봇 및 시스템 고안에 착수함.
    * 자율 주행 로봇을 통해 실시간 순찰 및 출입 감시를 수행하고, 원격 제어와 실시간 영상 확인이 가능한 통합 보안 체계를 구축하는 것을 목표로 함.
      
3.  **프로젝트 내용**
    * 자율주행 기반 항만 보안 순찰 로봇 개발
    * 자율주행 기능을 통해 사용자의 직접적인 조작 없이도 야적장 내부를 순찰하여 보안 사각지대 보완 및 항만시설 경비 시스템 강화
    * 밀입국, 불법 낚시 등 기존 경비 시스템 한계로 발생할 수 있는 인명 사고 및 각종 사고를 CV와 센서를 통해 사전 방지
    * 항만시설을 24시간 자율 순찰하며 사용자에게 모니터링 시스템 제공
    * 이상 상황 발생 시 CV와 센서를 통해 실시간 감지 및 보안 경고 알림 전송

### 3.2. 기술 현황 및 차별성

1.  **국내/외 기술 현황**
    * **롯데이노베이트, 자율주행 보안∙안전 로봇 ‘두루아이’:** 공장, 빌딩 외곽 등에서 열화상 카메라로 가스 및 화재를 탐지하고 객체 인식 기반 침입자 감지 시스템과 중앙제어실 자동 연계 기능으로 시설물 보안 및 안전 이상 사고를 미연에 방지
    * **관악구∙부산 등 지자체 스마트 순찰 로봇 :** 자율주행 로봇이 순찰지역의 영상, 화재, 이상소음 등을 점검하여 관제센터로 상황과 영상정보를 송신하는 로봇 기반 관제 시스템 탑재
      
2.  **작품의 특징 및 장점 (차별성)**
    * **활용성 :** 실내에 국한되지 않고 실외 환경에서 정찰이 가능함. SLAM 기능을 통해 항만시설 외 공항이나 군사 시설과 같이 보안과 사고에 민감한 장소에서 활용 가능
    * **집중 순찰 :** 단순히 주기적 순찰을 하는 것이 아니라, 사고 발생 빈도가 높은 특정 구역(웨이 포인트) 를 설정하여 집중 순찰이 가능합니다. 이는 기존 순찰 로봇이 단순 반복 순찰만 제공하는 것과 차별화됨
    * **항만 특화 :** 항만에서 특히 문제가 되는 4대 유독가스(일산화탄소, 암모니아, 메탄, 황화수소)와 산소 농도까지 감지할 수 있도록 설계되어 있습니다. 일반 순찰 로봇이 보안 중심이라면, 본 작품은 항만 산업 환경에 특화된 안전 모니터링 기능을 갖춘 것이 특징임
    * **구조적 위험 인식 :** 단순히 사람이나 화재만 보는 것이 아니라, 균열·뒤틀림 같은 구조적 위험 요소까지 인식할 수 있습니다. 이는 항만 하역 장비, 크레인, 컨테이너 구조물 등 대형 설비의 사고를 예방할 수 있다는 점에서 독창성이 있음

<br/>
<br/>

# 4. System Architecture (시스템 구성도)

| 제어기 | 센서 | 
|:------:|:------:|
| <img src="https://github.com/user-attachments/assets/15148a0a-46f6-4c63-834a-93b72df64159" alt="제어기" width="1200"> | <img src="https://github.com/user-attachments/assets/0d30d4a0-fa53-4b14-a850-6cb265bd3131" alt="센서" width="1200"> |

<br/>
<br/>

| 각 MCU가 담당하는 기능 | 시스템 흐름도 | 아두이노를 이용한 센서 제어 흐름도 |
|:------:|:------:|:------:|
| <img src="https://github.com/user-attachments/assets/2cd1bfd7-cdfc-4e3f-b960-09a95eb1c014" alt="MCU 구성도" width="800"> | <img src="https://github.com/user-attachments/assets/58e95ed4-c2e2-4cb4-b98a-9cd995c77c0d" alt="시스템 흐름도" width="800"> | <img src="https://github.com/user-attachments/assets/b8684c5e-5911-4047-8f60-38eb51c29b31" alt="아두이노 센서 제어 흐름도" width="800"> |

<br/>
<br/>

| 3가지의 CV 모델 시스템 흐름도 | 주행 경로 판단 및 장애물 회피(SLAM) 흐름도 | 경보 및 모니터링 시스템 흐름도 |
|:------:|:------:|:------:|
| <img src="https://github.com/user-attachments/assets/9770aad4-fbab-499a-8dd3-6206409c7801" alt="3가지의 CV 모델 시스템 흐름도" width="800"> | <img src="https://github.com/user-attachments/assets/7dda2eb9-1ff9-4856-b44d-e88c2ea54337" alt="주행 경로 판단 및 장애물 회피(SLAM) 흐름도" width="800"> | <img src="https://github.com/user-attachments/assets/8bbb91eb-c44e-45a1-94fe-b8fe610e4faa" alt="경보 및 모니터링 시스템 흐름도" width="800"> |


<br/>
<br/>

# 5. Technology Stack (기술 스택)

| 구분 | | 상세 내용 |
| :--- | :--- | :--- |
| **S/W 개발환경** | OS | Linux(Ubuntu 20.04), Window |
| | 개발환경(IDE) | VS Code, Arduino IDE |
| | 개발도구 | Streamlit, OpenCV, Ultralytics YOLO, MongoDB, HiveMQ |
| | 개발언어 | Python |
| **H/W 구성장비** | 디바이스 | Jetson orin nano, Arduino mega, Web Cam, R1 mini |
| | 센서 | Lidar, 산소 측정 센서, 가스 감지 센서, 불꽃 감지 센서, 적외선 거리 센서 |
| | 통신 | ROS2, MQTT, UART |
| | 언어 | Python, C/C++ |
| | 기타사항 | Speaker |
| **프로젝트 관리환경** | 형상관리 | Github |
| | 의사소통관리 | Notion, Github, 카카오톡 |

<br/>
<br/>

# 6. Core Technologies (주요 적용 기술)

1.  **침입자 인식 시스템**
    * 항만시설의 작업자는 모두 인가된 작업 조끼를 착용하고 다니기 때문에, Yolo를 통하여 사람과 Hi-Vis(인가된 작업 조끼)을 인식하여 사람의 bounding box 안에 Hivis의 bounding box가 포함되면 작업자라고 판단하고 Hivis를 포함하지 않은 사람 bounding box가 있는 경우에 낯선사람으로 간주하여 경보를 울리고 모니터링 시스템에 알림을 전송함
2.  **주행 경로 판단 및 장애물 회피**
    * 2D LiDAR를 이용하여 주변 장애물의 위치를 인식. LiDAR 센서로부터 획득한 데이터를 기반으로 SLAM을 수행하여 로봇의 위치를 추정하고 지도를 작성후 생성된 SLAM 기반 지도를 활용하여 장애물을 회피하고 주행 경로를 계획. 최종적으로 계획된 경로를 따라 로봇이 자율적으로 주행함.
3.  **경보 및 모니터링 시스템**
    * 낯선 사람 감지, 화재 발생, 유독 가스 노출 등 이상 상황 발생 시 부착된 센서와 CV로 감지하고 경보를 통해 주변 작업자에게 알림 또한 모니터링 시스템을 제공하여 실시간 경비 상황을 감시할 수 있게 하며 이상 상황 발생 시 경보 알림을 보내서 사용자에게 알릴 수 있음
4.  **센서**
    * 산소 센서, 가스 감지 센서(CO, CH4, C2H5OH, C3H8, C4H10, H2, H2S 및 NH3의 가스 농도)로 항만 내 유독 가스 및 화재를 감지하여 이상 상황을 빠르게 감지하여 대처할 수 있도록 함. 또한 LiDAR로 장애물을 감지하여 안정적으로 주행함
5.  **CV (Computer Vision)**
    * Hi-Vis(인가된 작업 조끼), 화재(불꽃), 항만 도로 균열을 **YOLO**로 실시간 탐지·분류하고, 알림/로그/대시보드로 전송하여 항만시설 내 사고 예방에 기여함

<br/>
<br/>

# 7. Implementation Details (기능 구현 상세)

### 7.1. S/W 개발 기능 상세

| 기능 | 설명 | 사진 |
| :--- | :--- | :--- |
| **Hi-Vis(인가된 작업 조끼) 착용 여부 판별 모델을 이용한 침입자 감지** | Jetson Orin에 연결된 USB 웹캠을 통해 실시간으로 수집된 영상에서 TensorRT engine으로 변환된 YOLO 모델을 노드 구동하여, 사람과 Hi-Vis(인가된 작업 조끼)를 탐지 <br/> <br/>탐지 결과를 별도의 대시보드에서 수신·시각화하여 실시간 모니터링 시스템에서 사람의 Bounding Box 안에 Hi-Vis(인가된 작업 조끼)의 Bounding Box가 포함되는지 확인 | <div align="center"><img src="https://github.com/user-attachments/assets/a0784b27-0b96-4a03-b3f1-c9b6ee2b4ab7" alt="Hi-Vis 감지" width="400"/></div> |
| **CV 모델을 이용한 화재 감지** | Jetson Orin에 연결된 USB 웹캠을 통해 실시간으로 수집된 영상에서 TensorRT engine으로 변환된 YOLO 모델을 노드 구동하여, 화재를 탐지 <br/>탐지 결과를 별도의 대시보드에서 수신·시각화하여 실시간 모니터링 시스템에서 확인 | <div align="center"><img src="https://github.com/user-attachments/assets/2d8f0c8d-dbbd-44aa-a826-1102d59dce15" alt="화재 감지" width="400"/></div> |
| **CV 모델을 이용한 도로 균열 감지** | Jetson Orin에 연결된 USB 웹캠을 통해 실시간으로 수집된 영상에서 TensorRT engine으로 변환된 YOLO 모델을 노드 구동하여, 4종류의 도로 균열을 실시간으로 확인함  <br/><br/>탐지 결과를 별도의 대시보드에서 수신·시각화하여 실시간 모니터링 시스템에서 확인 | <div align="center"><img src="https://github.com/user-attachments/assets/69e09f2a-e380-418c-8877-c92dc699ac45" alt="도로 균열 감지" width="400"/></div> |
| **주행 경로 판단 및 장애물 회피** | LiDAR 기반 Cartographer를 이용하여 실시간으로 지도 작성 및 자기 위치 추정을 수행  <br/><br/>작성된 지도를 Nav2에 연동하여 경로 계획 및 자율주행 판단을 수행  <br/> <br/>적외선 센서를 융합하여 근거리 장애물 회피 기능을 보완 | <div align="center"><img src="https://github.com/user-attachments/assets/216c00b1-e57f-4e46-821f-3bd327413b0f" alt="SLAM 지도1" width="400"/><img src="https://github.com/user-attachments/assets/8df54c61-9b5b-4a1b-9596-1b76314a5fa3" alt="SLAM 지도2" width="400"/></div> |
| **모니터링 시스템** | Streamlit 기반의 웹 대시보드를 통해 로봇이 수집한 센서 데이터와 알림 정보를 실시간으로 수신 및 시각화  <br/><br/>MongoDB와 연동하여 MQTT 통신을 통해 로봇에서 발생한 이벤트(화재, 안전조끼 미착용 등)와 센서 데이터(CH₄, CO, NO₂, O₂, NH₃ 등)를 저장하고 경보 내역을 표시  <br/><br/>센서의 현재 값과 변화 추세를 그래프로 시각화 | <div align="center"><img src="https://github.com/user-attachments/assets/7d20c138-585a-43af-aaec-a29d805b9397" alt="모니터링1" width="400"/><img src="https://github.com/user-attachments/assets/8693614c-92ae-4c15-bcbc-0fee4c197d89" alt="모니터링2" width="400"/></div> |
<br/>
<br/>

### 7.2. H/W 개발 기능 상세

| 기능/부품 | 설명 | 사진 |
| :--- | :--- | :---: |
| **구동부 모듈** | 실외 환경 주행 가능한 플랫폼 | <img src="https://github.com/user-attachments/assets/31f3d0b6-6974-46b4-9cbe-e11cb3ecde80" alt="image" width="400"/>|
| **LiDAR** | 자율주행 로봇에서 SLAM, Mapping, Localization, 경로 계획(Nav2) 같은 기능을 수행하려면 필요한 핵심 센서 | <img src="https://github.com/user-attachments/assets/5aaf5f7d-5f55-4d10-8ed6-44dff684e71f" alt="image" width="400"/> |
| **USB 웹캠** | CV 모델 활용을 위한 촬영장비, 현재 로봇에 달아두지 않았지만 추후 앞이 잘 보이는 곳에 장착 예정 | <img src="https://github.com/user-attachments/assets/fff90609-e24b-46c6-b071-c680b93b10e0" alt="image" width="400"/> |
| **적외선 거리 센서** | 근거리 물체/장애물 감지를 위한 보조 센서로 SLAM의 안정성과 정밀성을 높이는 역할을 수행함 | <img src="https://github.com/user-attachments/assets/67d7d2cc-a31c-4181-a01c-1b645840f0ee" alt="적외선 센서" width="400"/> |
| **가스 감지 센서** | 항만 4대 가스는 CO(일산화탄소), CH₄(메탄), H₂S(황화수소), NH₃(암모니아)로 인명사고와 폭발 위험이 큰 물질들 <br/> 본 프로젝트의 센서는 C₂H₅OH(에탄올), C₃H₈(프로판), C₄H₁₀(부탄), H₂(수소) 등도 추가로 감지 가능.</li></ul> | <img src="https://github.com/user-attachments/assets/da7d7add-76ad-4fd5-866f-3cc9674f6a0c" alt="가스 센서" width="400"/> |
| **산소 센서** | 대기 중 산소 농도가 18% 이하로 떨어질 경우 질식 위험이 발생함. 밀폐·반폐쇄 공간에서 산소 저하를 실시간으로 확인 | <img src="https://github.com/user-attachments/assets/0a61a821-9ae9-4de6-8685-c527f2dceb86" alt="산소 센서" width="400"/> |
| **불꽃 감지 센서** | 화재 발생 여부를 빠르게 감지하는 불꽃 감지 센서를 적용하여 CV 기반 화재 인식 기능을 보조함 | <img src="https://github.com/user-attachments/assets/60058449-e144-4fec-ab05-a089dee86b67" alt="불꽃 센서" width="400"/> |
| **Arduino Mega** | 센서들(LiDAR 제외)을 통합 제어하고 데이터 패킷 형태로 변환하여 Jetson Orin Nano로 전송함 | <img src="https://github.com/user-attachments/assets/dc5bc2fa-4fa7-41b7-ad76-75817cec2831" alt="Arduino Mega" width="400"/> |
| **Speaker** | CV 결과에 따라 경보음을 출력하기 위한 장치 | <img src="https://github.com/user-attachments/assets/425311cd-3014-4243-ad11-380596cf61f6" alt="스피커" width="400"/> |

<br/>
<br/>

# 8. Project Value (기타 사항 및 가치)

1.  **차별화된 성능** : 기존 정찰 로봇들은 주로 실내 환경이나 평탄한 도로와 같은 일반적인 조건에서만 활용되도록 설계되어, 야적장과 같이 불규칙한 지형·장애물·먼지·기상 변화가 많은 환경에서는 안정적으로 운용하기 어려움 경비 로봇 PORTY는 LiDAR, 카메라 등 다양한 센서를 적용하여 복잡한 실외 환경에서도 정확한 지도 작성과 자율 주행을 수행할 수 있음 따라서 야적장 뿐만 아니라, 공장·산업단지 등 다른 정찰이 필요한 장소에서도 활용 가능한 범용성이 있음

2.  **신뢰성** : LiDAR, 카메라, 가스·화재 센서 등 다양한 센서를 적용하여 단일 센서가 가진 한계를 상호 보완함 야간이나 안개 상황에서는 카메라 인식 정확도가 떨어질 수 있지만 LiDAR를 통해 거리·장애물 정보를 안정적으로 확보할 수 있으며, 반대로 LiDAR가 잡아내지 못하는 인물의 특성은 YOLO 기반 카메라 분석으로 정밀하게 탐지 가능함 SLAM·YOLO와 같은 검증된 알고리즘을 기반으로 경로 탐색, 객체 인식, 이상 상황 탐지 등의 핵심 기능을 수행하므로, 신뢰도 높은 실시간 대응이 가능함

3.  **사용성** : 자율주행 기능을 통해 사용자의 직접적인 조작 없이도 야적장 내부를 스스로 순찰하며, 경로 탐색·장애물 회피·상황 인식을 수행하기 때문에사용자가 로봇의 움직임을 지속적으로 감시하거나 제어할 필요가 없음 침입자 발생·화재·가스 누출과 같이 즉각적인 대응이 필요한 상황이 감지될 경우 로봇이 자동으로 무선 통신을 통해 알람과 현장 정보를 전송하여 사용자가 필요한 순간에만 개입하면 되므로, 상시 모니터링 부담이 줄고 관리 효율성이 향상됨  

4.  **보안** : 야적장은 자재와 장비가 대량으로 적치되는 공간으로, 침입·도난·화재·안전사고 발생 위험이 높지만 넓고 복잡한 지형 특성 때문에 기존의 CCTV나 경비 인력만으로는 보안 사각지대를 완전히 해소하기 어려움 본 프로젝트의 로봇은 야적장 전체를 스스로 순찰하며, 허가되지 않은 인물의 침입·화재나 가스 누출과 같은 이상 상황·예상치 못한 장애물을 실시간으로 감지하고 위험 상황이 발생하면 즉시 알람 및 현장 영상을 무선 통신으로 관리자에게 전송하여 신속한 대응을 가능하게 함 이를 통해, 사용자는 24시간 무인 보안 체계를 구축할 수 있으며, 기존 인력 중심 경비 방식보다 비용 효율적이면서도 더 높은 수준의 안전성을 확보할 수 있음  <br/>

5.  **알고리즘의 창작성** :
    **야적장 특화 환경 인식** - 기존 로봇은 평탄한 도로나 실내 환경에 활용되도록 설계되었으나, 본 프로젝트는 LiDAR· 적외선 거리 센서, 카메라·가스/화재 센서를 융합하여 비정형 지형·자재 이동·기상 변화가 많은 야적장에서도 안정적으로 주행하고 이상 상황을 인식할 수 있음
    **알람 우선순위화 알고리즘** - 기존 시스템은 단순 이벤트 감지 후 무조건 알람 전송하도록 설계 되어있으나, 본 프로젝트는 센서와 CV 등으로 특정 상황을 직접 감지하고 판단하여 중요 이벤트만 선별 전달하기 때문에 불필요한 경보가 감소하고 신뢰성이 향상됨
   
6.  **데이터와 프로그램의 가치** : 순찰·감시·이상 상황 대응을 자동화하여 보안 운영 효율성을 극대화하며, 모듈화된 구조를 통해 다양한 산업 분야에 확장·재사용 가능성을 지니고 있음 또한 로봇 운용 과정에서 수집되는 데이터를 활용해 알고리즘을 지속적으로 개선함으로써, 시간이 지날수록 더 높은 성능과 신뢰성을 확보할 수 있을 것으로 예상됨

<br/>
<br/>

# 9. Future Improvements (향후 개선 사항)

1) **모니터링 시스템 UI 개선**  
- 현재 구축된 모니터링 환경은 알림 기록 확인 기능과 각 센서의 상태를 확인할 수 있는 기능을 포함한 기능을 중심으로 구성되어 있는 형태  
- 향후, 로봇의 위치와 실시간 영상을 한 화면에서 직관적으로 모니터링할 수 있는 사용자 친화적인 UI로 개선할 예정  
- 다중 로봇의 상태를 동시에 관리할 수 있는 대시보드 형태의 인터페이스를 도입  
- 운영 효율성을 높이고, 이벤트 발생 시 즉각적으로 재생하거나 확대 확인할 수 있는 기능을 추가해 실시간 대응 능력을 강화할 계획  

2) **DB를 통한 다시보기 기능 연동**  
- 현재 시스템은 MongoDB와 연동되어 로봇이 수집한 센서 데이터와 알림 정보가 데이터베이스에 저장되는 형태  
- 다만, 사고 발생 시 원인을 추적할 수 있는 다시보기(영상 재생) 기능은 아직 구현되지 않은 상태  
- 영상 데이터까지 DB에 함께 저장하거나 외부와 연동하여, 관리자가 특정 시간대나 이벤트(침입, 화재, 가스 감지 등)를 선택하면 해당 시점의 영상을 재생할 수 있는 기능을 추가할 계획  
- 검색 기능을 통해 사건 유형별, 시간대별, 위치별 기록을 신속히 확인할 수 있도록 하여 보안 대응의 효율성을 높일 예정  

3) **야간 운용**  
- 항만은 24시간 운영되므로 로봇 또한 주야간 환경에서 안정적으로 운용될 수 있어야 함  
- 향후 IR 카메라 및 열화상 센서를 추가하여 야간이나 조도가 낮은 환경에서도 침입자 및 이상 상황을 탐지할 수 있도록 할 계획  
- AI 모델을 야간 데이터로 재학습시켜 낮/밤 환경에 따른 인식 정확도의 편차를 최소화할 예정  
- 필요 시 적외선 조명과 함께 활용하여 탐지율을 높일 예정  

4) **정확한 위치 전송을 위한 센서 추가**  
- 기존 로봇은 기본적인 주행 및 지도 작성 기능을 제공하고 있으나, GPS 및 센서 융합 기반의 정밀 위치 전송 기능을 강화할 필요가 있음  
- SLAM을 결합하여 항만 내 1m 이내의 오차 범위를 달성하는 것을 목표로 하여 관리자에게 보다 신뢰할 수 있는 위치 정보를 제공  
- 추후 항만 내 출입 관리 시스템과도 연계하여 확장 가능  

5) **외관 커버 제작**  
- 현재 센서들이 외부에 드러나 있는 상태임  
- 이에 따라 센서 보호를 위해 겉을 감싸는 커버 제작 예정  
<br/>
<br/>

# 10. References (참고자료)

| 부품명 | 모델명 | 관련 링크 |
|:------:|:--------|:-----------|
| **가스 센서** | MICS-1554 | [GitHub Repository](https://github.com/dfrobot/DFRobot_MICS) <br/> [제품 Wiki](https://wiki.dfrobot.com/Fermion__MEMS_Gas_Sensor___MiCS-5524_SKU_SEN0440) |
| **산소 센서** | I2C Oxygen Sensor [SEN0322] | [GitHub Repository](https://github.com/DFRobot/DFRobot_OxygenSensor) <br/> [제품 Wiki](https://wiki.dfrobot.com/Gravity_I2C_Oxygen_Sensor_SKU_SEN0322) |
| **LiDAR 센서** | YDLIDAR X4 PRO | [공식 제품 페이지 (YD LiDAR)](https://ko.ydlidar.com/product/ydlidar-x4-pro) |
